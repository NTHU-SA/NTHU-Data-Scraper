name: Run Scraper and Deploy

on:
  schedule:
    - cron: '0 16 * * *'  # 每天 UTC+8 的 00:00 執行（UTC 16:00 對應 UTC+8 00:00）
  push:
    branches:
      - main
  workflow_dispatch:  # 手動觸發

jobs:
  scrape-and-publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
            python-version: '3.12'

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Scrape Bus Data
        run: python scrapers/buses.py || true
    
      - name: Scrape Dining Data
        run: python scrapers/dining.py || true

      #- name: Scrape Directory Data
      #  run: python scrapers/directory.py || true

      #- name: Scrape Maps Data
      #  run: python scrapers/maps.py || true

      #- name: Scrape Newsletter Data
      #  run: python scrapers/newsletter.py || true

      - name: Scrape Course Data
        run: python scrapers/courses.py || true

      - name: Combine JSON Files
        run: python combine.py || true

      - name: Prepare Docs Folder
        run: |
            mkdir -p docs
            rm -rf docs/*
            cp -r json/. docs/
            python folder.py || true

      - name: Deploy to gh-pages Branch
        run: |
            git config --global user.name "github-actions"
            git config --global user.email "github-actions@github.com"

            # 取得 main 分支最新狀態
            git fetch origin main

            # 切換到 gh-pages 分支，若不存在則建立
            git checkout gh-pages 2>/dev/null || git checkout --orphan gh-pages

            # 將 main 分支的變更合併進來，保留 gh-pages 的 commit history
            git merge origin/main --no-edit || echo "Merge conflicts, please resolve manually"

            # 將新產生的 docs 資料夾內容複製進來
            cp -r docs/* .

            git add .
            git commit -m "action: Update scraped docs" || echo "No changes to commit"
            git push origin gh-pages
